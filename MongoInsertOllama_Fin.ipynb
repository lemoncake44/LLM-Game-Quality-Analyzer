{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83077d98-fdb7-4ea7-8692-1c48707ef051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import unicodedata\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e4df875-0d14-4b18-a831-7acfa67bf2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# CONFIGURATION SECTION\n",
    "#-------------------------------\n",
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "DB_NAME = 'games_database'\n",
    "POSTS_COLLECTION_NAME = 'games_posts_comments'\n",
    "COMMENTS_COLLECTION_NAME = 'games_posts_comments'\n",
    "\n",
    "OLAMA_ENDPOINT = 'http://localhost:11434/api/embeddings'\n",
    "EMBED_MODEL = 'nomic-embed-text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be58ebe5-cf73-4797-bb80-89cc6c382b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\aprna\\anaconda3\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain) (0.3.56)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain) (0.3.35)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\aprna\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aprna\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\aprna\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (2.1)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\aprna\\anaconda3\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.4.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.52 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.3.56)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.3.35)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aprna\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.11.3)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aprna\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "#Import langchain and ollama\n",
    "!pip install langchain\n",
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da1c8bd8-d381-4afd-9142-b27e5fcaefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#Initialize Ollama LLM\n",
    "llm = OllamaLLM(model=\"mistral-nemo\")\n",
    "\n",
    "#Create the prompt\n",
    "filter_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Given the following text, determine if it is relevant to a game review.\n",
    "    If relevant, return 'KEEP'. If irrelevant, return 'REMOVE'.\n",
    "\n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#Use RunnableSequence\n",
    "filter_chain = filter_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81a2327d-c8d5-416c-a819-6e0f3e4a18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "#-------------------------------\n",
    "# FUNCTION DEFINITIONS\n",
    "#-------------------------------\n",
    "\n",
    "def parse_timestamp(epoch_float):\n",
    "    if pd.isna(epoch_float):\n",
    "        return None\n",
    "    return datetime.fromtimestamp(float(epoch_float), tz=timezone.utc)\n",
    "    \n",
    "def clean_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    # Normalize Unicode to ASCII\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', ' ', text)\n",
    "    # Remove all characters except a-z and spaces\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # Remove all numbers\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Limit to first 500 words (if needed)\n",
    "    words = text.strip().split()\n",
    "    if len(words) > 500:\n",
    "        words = words[:500]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d3b764-ff14-48b5-a354-3e4959ae93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# READ THE EXCEL FILES\n",
    "#-------------------------------\n",
    "posts_df = pd.read_excel('C:/Users/aprna/Desktop/Reddit Scraper/Fin scraped/Final_MD_Posts.xlsx')\n",
    "comments_df = pd.read_excel('C:/Users/aprna/Desktop/Reddit Scraper/Fin scraped/Final_MD_Comments.xlsx')\n",
    "\n",
    "posts_df = posts_df.where(pd.notnull(posts_df), None)\n",
    "comments_df = comments_df.where(pd.notnull(comments_df), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0eff65-5cfd-4c6c-839a-012f152e5e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 0, 'ok': 1.0}, acknowledged=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------\n",
    "# CONNECT TO MONGODB\n",
    "#-------------------------------\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "posts_collection = db[POSTS_COLLECTION_NAME]\n",
    "comments_collection = db[COMMENTS_COLLECTION_NAME]\n",
    "\n",
    "posts_collection.delete_many({})\n",
    "comments_collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce9d7692-6a6b-4f28-8ef8-c2f9f921cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [42:09<00:00, 19.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inserted 30 posts into MongoDB.\n",
      "\n",
      "ðŸ“‹ Sample Inserted Posts:\n",
      "{'_id': ObjectId('680c3364de6ff9399c3bbb2d'), 'post_id': '1jbg678', 'title': \"Should I buy Every Assassin's Creed Game?\", 'selftext': \"Spring Steam Sale is here and like the whole Assassin's Creed Franchise is on sale for like 85 plus I was thinking of getting Assassin's Creed Shadows as well.\\nI have played the Ezio games on the PS3 but not on PC and I haven't played the latest Assassin's Creed games.\\nShould I buy everything or just some of them since I plan on buying Assassin's Creed Shadows as well?\", 'selftext_cleaned': 'spring steam sale is here and like the whole assassin s creed franchise is on sale for like plus i was thinking of getting assassin s creed shadows as well i have played the ezio games on the ps but not on pc and i haven t played the latest assassin s creed games should i buy everything or just some of them since i plan on buying assassin s creed shadows as well', 'author': 'DRN56', 'created_date': datetime.datetime(2025, 3, 14, 22, 26, 4)}\n",
      "{'_id': ObjectId('680c3364de6ff9399c3bbb2e'), 'post_id': '1ji5ih9', 'title': \"Assassin's Creed Shadows vs Xenoblade Chronicles X: DE, what's the better open-world RPG experience?\", 'selftext': \"1. Looking for an open-world RPG that emphasis immersive exploration and rewards it with very little handholding, like Elden Ring.\\n2. I'm a big fan of JRPGS (Persona, FF, CT, Valkyrie Profile, Bloodborne), but have also enjoyed the AC games during the Xbox 360/PS3 generation, and AC: Origins. Love stealth games too.\\n3. I'm looking for an RPG I can immerse myself in for 60-100+ that doesn't suffer from repetition and has engaging gameplay systems/mechanics.\\n4. Great side content and an addicting gameplay loop is a big + for me.\\n5. Gameplay challenge is important, I'll get bored if it's too easy.\", 'selftext_cleaned': 'looking for an open world rpg that emphasis immersive exploration and rewards it with very little handholding like elden ring i m a big fan of jrpgs persona ff ct valkyrie profile bloodborne but have also enjoyed the ac games during the xbox ps generation and ac origins love stealth games too i m looking for an rpg i can immerse myself in for that doesn t suffer from repetition and has engaging gameplay systems mechanics great side content and an addicting gameplay loop is a big for me gameplay challenge is important i ll get bored if it s too easy', 'author': 'Marinebiologist_0', 'created_date': datetime.datetime(2025, 3, 23, 18, 6, 16)}\n",
      "{'_id': ObjectId('680c3364de6ff9399c3bbb2f'), 'post_id': '1ji227j', 'title': \"Montser Hunter Wilds, Assassin's Creed Shadows or Atomicfall\", 'selftext': \"Which game should I buy? I can either play it on PC or PS5. I don't have the worst PC right, but I also don't have top of the line either. It's probably 4 ish years old. I play solo the majority of my time, if any of the games are able, I also play mostly on my steam deck. I have a kid around a year old so that's why I play mostly solo and on my steam deck. Thanks for your help! \", 'selftext_cleaned': 'which game should i buy i can either play it on pc or ps i don t have the worst pc right but i also don t have top of the line either it s probably ish years old i play solo the majority of my time if any of the games are able i also play mostly on my steam deck i have a kid around a year old so that s why i play mostly solo and on my steam deck thanks for your help', 'author': 'Fun-Tomato-4903', 'created_date': datetime.datetime(2025, 3, 23, 15, 39, 30)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "#Mistral Nemo will run through all posts and accept of reject them\n",
    "post_docs = []\n",
    "\n",
    "for _, row in tqdm(posts_df.iterrows(), total=posts_df.shape[0]):\n",
    "    cleaned_text = clean_text(row.get('selftext'))\n",
    "\n",
    "    try:\n",
    "        # pass 'text' matching prompt\n",
    "        filter_result = filter_chain.invoke({\"text\": cleaned_text})\n",
    "\n",
    "        if isinstance(filter_result, dict):\n",
    "            filter_result = filter_result.get('text')\n",
    "        filter_result = filter_result.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error filtering post: {e}\")\n",
    "        filter_result = \"REMOVE\"\n",
    "\n",
    "    if filter_result == \"KEEP\":\n",
    "        doc = {\n",
    "            \"post_id\": row.get('post_id'),\n",
    "            \"title\": row.get('title'),\n",
    "            \"selftext\": row.get('selftext'),\n",
    "            \"selftext_cleaned\": cleaned_text,\n",
    "            \"author\": row.get('author'),\n",
    "            \"created_date\": parse_timestamp(row.get('created_utc')),\n",
    "        }\n",
    "        post_docs.append(doc)\n",
    "\n",
    "#After processing\n",
    "if post_docs:\n",
    "    posts_collection.insert_many(post_docs)\n",
    "    print(f\"âœ… Inserted {len(post_docs)} posts into MongoDB.\")\n",
    "\n",
    "    # Show a sample of inserted posts\n",
    "    sample_posts = posts_collection.find().limit(3)  # change 3 to however many you want\n",
    "    print(\"\\nðŸ“‹ Sample Inserted Posts:\")\n",
    "    for post in sample_posts:\n",
    "        print(post)\n",
    "else:\n",
    "    print(\"âš ï¸ No posts inserted (no posts passed filtering).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3df9d48d-bea7-45d4-a093-7d77ca6291f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ DataFrame Created from Inserted Posts:\n",
      "   post_id                                              title  \\\n",
      "0  1jbg678          Should I buy Every Assassin's Creed Game?   \n",
      "1  1ji5ih9  Assassin's Creed Shadows vs Xenoblade Chronicl...   \n",
      "2  1ji227j  Montser Hunter Wilds, Assassin's Creed Shadows...   \n",
      "3  1jmc72g  Need recommendations for a linear, non-open wo...   \n",
      "4  1j634m2  Monster Hunter Wilds has been out for a week n...   \n",
      "\n",
      "                                            selftext  \\\n",
      "0  Spring Steam Sale is here and like the whole A...   \n",
      "1  1. Looking for an open-world RPG that emphasis...   \n",
      "2  Which game should I buy? I can either play it ...   \n",
      "3  I'm currently playing Assassin's Creed Shadows...   \n",
      "4  Game: Monster Hunter Wilds\\n\\nInitial release ...   \n",
      "\n",
      "                                    selftext_cleaned             author  \\\n",
      "0  spring steam sale is here and like the whole a...              DRN56   \n",
      "1  looking for an open world rpg that emphasis im...  Marinebiologist_0   \n",
      "2  which game should i buy i can either play it o...    Fun-Tomato-4903   \n",
      "3  i m currently playing assassin s creed shadows...     keepfighting90   \n",
      "4  game monster hunter wilds initial release date...  Marinebiologist_0   \n",
      "\n",
      "               created_date                       _id  \n",
      "0 2025-03-14 22:26:04+00:00  680c3364de6ff9399c3bbb2d  \n",
      "1 2025-03-23 18:06:16+00:00  680c3364de6ff9399c3bbb2e  \n",
      "2 2025-03-23 15:39:30+00:00  680c3364de6ff9399c3bbb2f  \n",
      "3 2025-03-29 02:19:07+00:00  680c3364de6ff9399c3bbb30  \n",
      "4 2025-03-07 23:11:43+00:00  680c3364de6ff9399c3bbb31  \n"
     ]
    }
   ],
   "source": [
    "#Build a DataFrame directly from what was inserted\n",
    "posts_df_final = pd.DataFrame(post_docs)\n",
    "print(\"\\nðŸ“‹ DataFrame Created from Inserted Posts:\")\n",
    "print(posts_df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59656c97-b8a0-4e58-aebf-156d9443a17e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned posts saved into 'cleaned_posts_final.csv' with 'title' cleaned.\n"
     ]
    }
   ],
   "source": [
    "#Apply clean_text to 'title' and temporarily store in 'title_cleaned'\n",
    "posts_df_final['title_cleaned'] = posts_df_final['title'].apply(clean_text)\n",
    "\n",
    "#Replace 'title' column with the cleaned version\n",
    "posts_df_final['title'] = posts_df_final['title_cleaned']\n",
    "\n",
    "#Drop the 'title_cleaned' helper column (no need to save it)\n",
    "posts_df_final = posts_df_final.drop(columns=['title_cleaned'])\n",
    "\n",
    "#Save the updated DataFrame to CSV\n",
    "posts_df_final.to_csv(\"cleaned_posts_final11.csv\", index=False)\n",
    "print(\"âœ… Cleaned posts saved into 'cleaned_posts_final11.csv' successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf2161-1fa3-4f33-af6d-6bc893d311dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 309/12464 [50:57<32:01:37,  9.49s/it] "
     ]
    }
   ],
   "source": [
    "#-------------------------------\n",
    "# PROCESS COMMENTS\n",
    "#-------------------------------\n",
    "print(\"Processing comments...\")\n",
    "\n",
    "comment_docs = []\n",
    "\n",
    "for _, row in tqdm(comments_df.iterrows(), total=comments_df.shape[0]):\n",
    "    cleaned_text = clean_text(row.get('comment_body'))\n",
    "\n",
    "    try:\n",
    "        # Match the new way: pass 'text' key\n",
    "        filter_result = filter_chain.invoke({\"text\": cleaned_text})\n",
    "\n",
    "        if isinstance(filter_result, dict):\n",
    "            filter_result = filter_result.get('text')\n",
    "        filter_result = filter_result.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error filtering comment: {e}\")\n",
    "        filter_result = \"REMOVE\"\n",
    "\n",
    "    if filter_result == \"KEEP\":\n",
    "        doc = {\n",
    "            \"comment_id\": row.get('comment_id'),\n",
    "            \"post_id\": row.get('post_id'),\n",
    "            \"comment_body\": row.get('comment_body'),\n",
    "            \"comment_body_cleaned\": cleaned_text,\n",
    "            \"author\": row.get('author'),\n",
    "            \"created_date\": parse_timestamp(row.get('created_utc')),  # fix here too\n",
    "            # embedding removed\n",
    "        }\n",
    "        comment_docs.append(doc)\n",
    "\n",
    "#After processing\n",
    "if comment_docs:\n",
    "    comments_collection.insert_many(comment_docs)\n",
    "    print(f\"âœ… Inserted {len(comment_docs)} comments into MongoDB.\")\n",
    "\n",
    "    # ðŸ”¥ Show a sample of inserted comments\n",
    "    sample_comments = comments_collection.find().limit(3)\n",
    "    print(\"\\nðŸ“‹ Sample Inserted Comments:\")\n",
    "    for comment in sample_comments:\n",
    "        print(comment)\n",
    "else:\n",
    "    print(\"âš ï¸ No comments inserted (no comments passed filtering).\")\n",
    "\n",
    "print(\"\\nETL Process Completed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b467de-90b2-4a59-9150-5a13900f3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the updated DataFrame to CSV\n",
    "comments_df_final.to_csv(\"cleaned_comments_final11.csv\", index=False)\n",
    "print(\"âœ… Cleaned commentss saved into 'cleaned_comments_final11.csv' successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (user-installed)",
   "language": "python",
   "name": "myuserenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "510d8e27-bcca-4ed4-a6d0-30c04df9d8c0"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
